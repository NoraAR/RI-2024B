{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8200261,"sourceType":"datasetVersion","datasetId":4750111}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:12.913200Z","iopub.execute_input":"2025-01-14T14:28:12.913581Z","iopub.status.idle":"2025-01-14T14:28:12.937830Z","shell.execute_reply.started":"2025-01-14T14:28:12.913551Z","shell.execute_reply":"2025-01-14T14:28:12.936649Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lex-fridman-podcast-transcript/podcastdata_dataset.csv\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import pandas as pd\narchivo_csv = '/kaggle/input/lex-fridman-podcast-transcript/podcastdata_dataset.csv'\ndf = pd.read_csv(archivo_csv)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:12.939144Z","iopub.execute_input":"2025-01-14T14:28:12.939479Z","iopub.status.idle":"2025-01-14T14:28:13.359478Z","shell.execute_reply.started":"2025-01-14T14:28:12.939450Z","shell.execute_reply":"2025-01-14T14:28:13.358309Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   id            guest                    title  \\\n0   1      Max Tegmark                 Life 3.0   \n1   2    Christof Koch            Consciousness   \n2   3    Steven Pinker  AI in the Age of Reason   \n3   4    Yoshua Bengio            Deep Learning   \n4   5  Vladimir Vapnik     Statistical Learning   \n\n                                                text  \n0  As part of MIT course 6S099, Artificial Genera...  \n1  As part of MIT course 6S099 on artificial gene...  \n2  You've studied the human mind, cognition, lang...  \n3  What difference between biological neural netw...  \n4  The following is a conversation with Vladimir ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>guest</th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Max Tegmark</td>\n      <td>Life 3.0</td>\n      <td>As part of MIT course 6S099, Artificial Genera...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Christof Koch</td>\n      <td>Consciousness</td>\n      <td>As part of MIT course 6S099 on artificial gene...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Steven Pinker</td>\n      <td>AI in the Age of Reason</td>\n      <td>You've studied the human mind, cognition, lang...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Yoshua Bengio</td>\n      <td>Deep Learning</td>\n      <td>What difference between biological neural netw...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Vladimir Vapnik</td>\n      <td>Statistical Learning</td>\n      <td>The following is a conversation with Vladimir ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"tokens = []\nfor i in range(len(df)):\n    tokens.append(df['text'][i].split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:13.361490Z","iopub.execute_input":"2025-01-14T14:28:13.361889Z","iopub.status.idle":"2025-01-14T14:28:14.410135Z","shell.execute_reply.started":"2025-01-14T14:28:13.361849Z","shell.execute_reply":"2025-01-14T14:28:14.409012Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"#Oraciones\nlen(df['text'][0].split('.'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:14.411919Z","iopub.execute_input":"2025-01-14T14:28:14.412341Z","iopub.status.idle":"2025-01-14T14:28:14.419607Z","shell.execute_reply.started":"2025-01-14T14:28:14.412300Z","shell.execute_reply":"2025-01-14T14:28:14.418342Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"611"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"#Palabras\nfor i in range(len(df)):\n    len(df['text'][i].split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:14.420660Z","iopub.execute_input":"2025-01-14T14:28:14.421317Z","iopub.status.idle":"2025-01-14T14:28:14.875899Z","shell.execute_reply.started":"2025-01-14T14:28:14.421277Z","shell.execute_reply":"2025-01-14T14:28:14.874673Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"texto = str(df[df['id'] == 2]['text'].values[0])\nlen(texto.split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:14.876836Z","iopub.execute_input":"2025-01-14T14:28:14.877248Z","iopub.status.idle":"2025-01-14T14:28:14.886433Z","shell.execute_reply.started":"2025-01-14T14:28:14.877204Z","shell.execute_reply":"2025-01-14T14:28:14.885141Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"10217"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"def wc(texto):\n    return len(texto.split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:14.887453Z","iopub.execute_input":"2025-01-14T14:28:14.887732Z","iopub.status.idle":"2025-01-14T14:28:14.902399Z","shell.execute_reply.started":"2025-01-14T14:28:14.887698Z","shell.execute_reply":"2025-01-14T14:28:14.901363Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"df['wc'] = df['text'].apply(wc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:14.905018Z","iopub.execute_input":"2025-01-14T14:28:14.905379Z","iopub.status.idle":"2025-01-14T14:28:15.332636Z","shell.execute_reply.started":"2025-01-14T14:28:14.905337Z","shell.execute_reply":"2025-01-14T14:28:15.331704Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def ws(texto):\n    return texto.split('.'),len(texto.split('.'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:15.333892Z","iopub.execute_input":"2025-01-14T14:28:15.334173Z","iopub.status.idle":"2025-01-14T14:28:15.339053Z","shell.execute_reply.started":"2025-01-14T14:28:15.334129Z","shell.execute_reply":"2025-01-14T14:28:15.337645Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"df[['text sentence', 'ws']] = df['text'].apply(lambda x: pd.Series(ws(x)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:15.340059Z","iopub.execute_input":"2025-01-14T14:28:15.340420Z","iopub.status.idle":"2025-01-14T14:28:15.742475Z","shell.execute_reply.started":"2025-01-14T14:28:15.340390Z","shell.execute_reply":"2025-01-14T14:28:15.741376Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:15.743659Z","iopub.execute_input":"2025-01-14T14:28:15.743991Z","iopub.status.idle":"2025-01-14T14:28:15.759843Z","shell.execute_reply.started":"2025-01-14T14:28:15.743953Z","shell.execute_reply":"2025-01-14T14:28:15.758602Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"   id            guest                    title  \\\n0   1      Max Tegmark                 Life 3.0   \n1   2    Christof Koch            Consciousness   \n2   3    Steven Pinker  AI in the Age of Reason   \n3   4    Yoshua Bengio            Deep Learning   \n4   5  Vladimir Vapnik     Statistical Learning   \n\n                                                text     wc  \\\n0  As part of MIT course 6S099, Artificial Genera...  13424   \n1  As part of MIT course 6S099 on artificial gene...  10217   \n2  You've studied the human mind, cognition, lang...   5989   \n3  What difference between biological neural netw...   5993   \n4  The following is a conversation with Vladimir ...   6374   \n\n                                       text sentence   ws  \n0  [As part of MIT course 6S099, Artificial Gener...  611  \n1  [As part of MIT course 6S099 on artificial gen...  499  \n2  [You've studied the human mind, cognition, lan...  292  \n3  [What difference between biological neural net...  311  \n4  [The following is a conversation with Vladimir...  514  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>guest</th>\n      <th>title</th>\n      <th>text</th>\n      <th>wc</th>\n      <th>text sentence</th>\n      <th>ws</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Max Tegmark</td>\n      <td>Life 3.0</td>\n      <td>As part of MIT course 6S099, Artificial Genera...</td>\n      <td>13424</td>\n      <td>[As part of MIT course 6S099, Artificial Gener...</td>\n      <td>611</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Christof Koch</td>\n      <td>Consciousness</td>\n      <td>As part of MIT course 6S099 on artificial gene...</td>\n      <td>10217</td>\n      <td>[As part of MIT course 6S099 on artificial gen...</td>\n      <td>499</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Steven Pinker</td>\n      <td>AI in the Age of Reason</td>\n      <td>You've studied the human mind, cognition, lang...</td>\n      <td>5989</td>\n      <td>[You've studied the human mind, cognition, lan...</td>\n      <td>292</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Yoshua Bengio</td>\n      <td>Deep Learning</td>\n      <td>What difference between biological neural netw...</td>\n      <td>5993</td>\n      <td>[What difference between biological neural net...</td>\n      <td>311</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Vladimir Vapnik</td>\n      <td>Statistical Learning</td>\n      <td>The following is a conversation with Vladimir ...</td>\n      <td>6374</td>\n      <td>[The following is a conversation with Vladimir...</td>\n      <td>514</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"df['ws'].sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:15.761184Z","iopub.execute_input":"2025-01-14T14:28:15.761622Z","iopub.status.idle":"2025-01-14T14:28:15.778045Z","shell.execute_reply.started":"2025-01-14T14:28:15.761568Z","shell.execute_reply":"2025-01-14T14:28:15.776869Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"390883"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"rows = []\nfor _, row in df.iterrows():\n    episode_id = row['id']\n    for idx, sentence in enumerate(row['text sentence'], start=1):\n        rows.append({'ep_id': episode_id, 'sentence_id': idx, 'text': sentence})\n\ndf_modelado = pd.DataFrame(rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:15.779073Z","iopub.execute_input":"2025-01-14T14:28:15.779458Z","iopub.status.idle":"2025-01-14T14:28:16.496184Z","shell.execute_reply.started":"2025-01-14T14:28:15.779425Z","shell.execute_reply":"2025-01-14T14:28:16.495115Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"oraciones_episodio_1 = df_modelado[df_modelado['ep_id'] == 1]\nprint(oraciones_episodio_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:16.497123Z","iopub.execute_input":"2025-01-14T14:28:16.497470Z","iopub.status.idle":"2025-01-14T14:28:16.506754Z","shell.execute_reply.started":"2025-01-14T14:28:16.497443Z","shell.execute_reply":"2025-01-14T14:28:16.505726Z"}},"outputs":[{"name":"stdout","text":"     ep_id  sentence_id                                               text\n0        1            1  As part of MIT course 6S099, Artificial Genera...\n1        1            2                      He is a professor here at MIT\n2        1            3   He's a physicist, spent a large part of his c...\n3        1            4   But he's also studied and delved into the ben...\n4        1            5   Amongst many other things, he is the cofounde...\n..     ...          ...                                                ...\n606      1          607   So speaking of software that nobody understan...\n607      1          608   But what are your thoughts on deep learning? ...\n608      1          609   What are your thoughts about the promise limi...\n609      1          610   One of them is when you look at the human bra...\n610      1          611                                                   \n\n[611 rows x 3 columns]\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# 1. Tokenización: Convertir frases en listas de palabras\ndf_modelado['tokens'] = df_modelado['text'].apply(lambda x: word_tokenize(x.lower()))\n\n# 2. Entrenamiento de Word2Vec\n# Crear una lista de listas de palabras (tokens) para entrenar Word2Vec\nsentences = df_modelado['tokens'].tolist()\n\n# Entrenar el modelo Word2Vec\nmodel = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:28:16.507762Z","iopub.execute_input":"2025-01-14T14:28:16.508135Z","iopub.status.idle":"2025-01-14T14:29:42.524038Z","shell.execute_reply.started":"2025-01-14T14:28:16.508098Z","shell.execute_reply":"2025-01-14T14:29:42.523143Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"pip install gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:29:42.525065Z","iopub.execute_input":"2025-01-14T14:29:42.525422Z","iopub.status.idle":"2025-01-14T14:29:46.601639Z","shell.execute_reply.started":"2025-01-14T14:29:42.525383Z","shell.execute_reply":"2025-01-14T14:29:46.600029Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import pandas as pd\nfrom gensim.models import Word2Vec\nfrom nltk.tokenize import word_tokenize\nimport nltk\n\n\n# 3. Obtener embeddings para cada frase\n# Función para promediar los vectores de palabras en cada oración\ndef obtener_embedding(tokens, model):\n    vectors = [model.wv[word] for word in tokens if word in model.wv]\n    if vectors:\n        return sum(vectors) / len(vectors)  # Promedio de vectores\n    else:\n        return [0] * model.vector_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:29:46.603265Z","iopub.execute_input":"2025-01-14T14:29:46.603590Z","iopub.status.idle":"2025-01-14T14:29:46.610866Z","shell.execute_reply.started":"2025-01-14T14:29:46.603553Z","shell.execute_reply":"2025-01-14T14:29:46.609571Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"df_modelado['embedding'] = df_modelado['tokens'].apply(lambda x: obtener_embedding(x, model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:29:46.612167Z","iopub.execute_input":"2025-01-14T14:29:46.612471Z","iopub.status.idle":"2025-01-14T14:30:07.148023Z","shell.execute_reply.started":"2025-01-14T14:29:46.612445Z","shell.execute_reply":"2025-01-14T14:30:07.146510Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"df_modelado","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:30:07.149182Z","iopub.execute_input":"2025-01-14T14:30:07.149574Z","iopub.status.idle":"2025-01-14T14:30:07.175909Z","shell.execute_reply.started":"2025-01-14T14:30:07.149530Z","shell.execute_reply":"2025-01-14T14:30:07.174535Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"        ep_id  sentence_id                                               text  \\\n0           1            1  As part of MIT course 6S099, Artificial Genera...   \n1           1            2                      He is a professor here at MIT   \n2           1            3   He's a physicist, spent a large part of his c...   \n3           1            4   But he's also studied and delved into the ben...   \n4           1            5   Amongst many other things, he is the cofounde...   \n...       ...          ...                                                ...   \n390878    325         1727                                 It's the beginning   \n390879    325         1728   It's not the whole story by any means, but it...   \n390880    325         1729   Where's state stored of the system? Is it in ...   \n390881    325         1730                     So there are chemical networks   \n390882    325         1731   So for example, gene regulatory networks, rig...   \n\n                                                   tokens  \\\n0       [as, part, of, mit, course, 6s099, ,, artifici...   \n1                   [he, is, a, professor, here, at, mit]   \n2       [he, 's, a, physicist, ,, spent, a, large, par...   \n3       [but, he, 's, also, studied, and, delved, into...   \n4       [amongst, many, other, things, ,, he, is, the,...   \n...                                                   ...   \n390878                           [it, 's, the, beginning]   \n390879  [it, 's, not, the, whole, story, by, any, mean...   \n390880  [where, 's, state, stored, of, the, system, ?,...   \n390881               [so, there, are, chemical, networks]   \n390882  [so, for, example, ,, gene, regulatory, networ...   \n\n                                                embedding  \n0       [0.19861163, 0.22445412, 0.59233624, -0.243688...  \n1       [0.35261315, 0.65616363, 0.33231214, -0.410016...  \n2       [-0.4165765, 0.32829908, 0.48733902, 0.1845713...  \n3       [-0.37365314, -0.5530812, 0.66169035, -0.64571...  \n4       [-0.30308935, -0.17375223, 0.26148164, -0.1791...  \n...                                                   ...  \n390878  [0.063448906, 0.6749759, 0.81553847, -0.434464...  \n390879  [-0.17980759, -0.34563464, 0.7182552, -0.23193...  \n390880  [-0.12897475, 0.11541487, 0.8889587, -0.710236...  \n390881  [0.3387075, -1.0429316, 0.19270645, -0.0287592...  \n390882  [-0.06072505, 0.15595824, 0.50161827, -0.63313...  \n\n[390883 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ep_id</th>\n      <th>sentence_id</th>\n      <th>text</th>\n      <th>tokens</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>As part of MIT course 6S099, Artificial Genera...</td>\n      <td>[as, part, of, mit, course, 6s099, ,, artifici...</td>\n      <td>[0.19861163, 0.22445412, 0.59233624, -0.243688...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>He is a professor here at MIT</td>\n      <td>[he, is, a, professor, here, at, mit]</td>\n      <td>[0.35261315, 0.65616363, 0.33231214, -0.410016...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>He's a physicist, spent a large part of his c...</td>\n      <td>[he, 's, a, physicist, ,, spent, a, large, par...</td>\n      <td>[-0.4165765, 0.32829908, 0.48733902, 0.1845713...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>But he's also studied and delved into the ben...</td>\n      <td>[but, he, 's, also, studied, and, delved, into...</td>\n      <td>[-0.37365314, -0.5530812, 0.66169035, -0.64571...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>Amongst many other things, he is the cofounde...</td>\n      <td>[amongst, many, other, things, ,, he, is, the,...</td>\n      <td>[-0.30308935, -0.17375223, 0.26148164, -0.1791...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>390878</th>\n      <td>325</td>\n      <td>1727</td>\n      <td>It's the beginning</td>\n      <td>[it, 's, the, beginning]</td>\n      <td>[0.063448906, 0.6749759, 0.81553847, -0.434464...</td>\n    </tr>\n    <tr>\n      <th>390879</th>\n      <td>325</td>\n      <td>1728</td>\n      <td>It's not the whole story by any means, but it...</td>\n      <td>[it, 's, not, the, whole, story, by, any, mean...</td>\n      <td>[-0.17980759, -0.34563464, 0.7182552, -0.23193...</td>\n    </tr>\n    <tr>\n      <th>390880</th>\n      <td>325</td>\n      <td>1729</td>\n      <td>Where's state stored of the system? Is it in ...</td>\n      <td>[where, 's, state, stored, of, the, system, ?,...</td>\n      <td>[-0.12897475, 0.11541487, 0.8889587, -0.710236...</td>\n    </tr>\n    <tr>\n      <th>390881</th>\n      <td>325</td>\n      <td>1730</td>\n      <td>So there are chemical networks</td>\n      <td>[so, there, are, chemical, networks]</td>\n      <td>[0.3387075, -1.0429316, 0.19270645, -0.0287592...</td>\n    </tr>\n    <tr>\n      <th>390882</th>\n      <td>325</td>\n      <td>1731</td>\n      <td>So for example, gene regulatory networks, rig...</td>\n      <td>[so, for, example, ,, gene, regulatory, networ...</td>\n      <td>[-0.06072505, 0.15595824, 0.50161827, -0.63313...</td>\n    </tr>\n  </tbody>\n</table>\n<p>390883 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\nembeddings = np.array(df_modelado['embedding'].tolist())\n\n# Número de clusters \nn_clusters = 5\n\n# Aplicar K-Means\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\ndf_modelado['cluster'] = kmeans.fit_predict(embeddings)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:30:07.177076Z","iopub.execute_input":"2025-01-14T14:30:07.177460Z","iopub.status.idle":"2025-01-14T14:30:35.145875Z","shell.execute_reply.started":"2025-01-14T14:30:07.177432Z","shell.execute_reply":"2025-01-14T14:30:35.144913Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"df_modelado[df_modelado['ep_id'] == 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:30:35.146958Z","iopub.execute_input":"2025-01-14T14:30:35.147278Z","iopub.status.idle":"2025-01-14T14:30:35.174437Z","shell.execute_reply.started":"2025-01-14T14:30:35.147251Z","shell.execute_reply":"2025-01-14T14:30:35.173295Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"     ep_id  sentence_id                                               text  \\\n0        1            1  As part of MIT course 6S099, Artificial Genera...   \n1        1            2                      He is a professor here at MIT   \n2        1            3   He's a physicist, spent a large part of his c...   \n3        1            4   But he's also studied and delved into the ben...   \n4        1            5   Amongst many other things, he is the cofounde...   \n..     ...          ...                                                ...   \n606      1          607   So speaking of software that nobody understan...   \n607      1          608   But what are your thoughts on deep learning? ...   \n608      1          609   What are your thoughts about the promise limi...   \n609      1          610   One of them is when you look at the human bra...   \n610      1          611                                                      \n\n                                                tokens  \\\n0    [as, part, of, mit, course, 6s099, ,, artifici...   \n1                [he, is, a, professor, here, at, mit]   \n2    [he, 's, a, physicist, ,, spent, a, large, par...   \n3    [but, he, 's, also, studied, and, delved, into...   \n4    [amongst, many, other, things, ,, he, is, the,...   \n..                                                 ...   \n606  [so, speaking, of, software, that, nobody, und...   \n607  [but, what, are, your, thoughts, on, deep, lea...   \n608  [what, are, your, thoughts, about, the, promis...   \n609  [one, of, them, is, when, you, look, at, the, ...   \n610                                                 []   \n\n                                             embedding  cluster  \n0    [0.19861163, 0.22445412, 0.59233624, -0.243688...        0  \n1    [0.35261315, 0.65616363, 0.33231214, -0.410016...        0  \n2    [-0.4165765, 0.32829908, 0.48733902, 0.1845713...        0  \n3    [-0.37365314, -0.5530812, 0.66169035, -0.64571...        0  \n4    [-0.30308935, -0.17375223, 0.26148164, -0.1791...        0  \n..                                                 ...      ...  \n606  [-0.15644458, -0.12002514, 0.52115595, -0.0703...        0  \n607  [-0.09975407, -0.10085674, 0.75640166, -0.0454...        3  \n608  [0.25803897, -0.4572116, 0.67869514, -0.127189...        0  \n609  [-0.06427292, -0.3188045, 0.48247167, -0.53355...        0  \n610  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0  \n\n[611 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ep_id</th>\n      <th>sentence_id</th>\n      <th>text</th>\n      <th>tokens</th>\n      <th>embedding</th>\n      <th>cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>As part of MIT course 6S099, Artificial Genera...</td>\n      <td>[as, part, of, mit, course, 6s099, ,, artifici...</td>\n      <td>[0.19861163, 0.22445412, 0.59233624, -0.243688...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>He is a professor here at MIT</td>\n      <td>[he, is, a, professor, here, at, mit]</td>\n      <td>[0.35261315, 0.65616363, 0.33231214, -0.410016...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>He's a physicist, spent a large part of his c...</td>\n      <td>[he, 's, a, physicist, ,, spent, a, large, par...</td>\n      <td>[-0.4165765, 0.32829908, 0.48733902, 0.1845713...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>But he's also studied and delved into the ben...</td>\n      <td>[but, he, 's, also, studied, and, delved, into...</td>\n      <td>[-0.37365314, -0.5530812, 0.66169035, -0.64571...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>Amongst many other things, he is the cofounde...</td>\n      <td>[amongst, many, other, things, ,, he, is, the,...</td>\n      <td>[-0.30308935, -0.17375223, 0.26148164, -0.1791...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>606</th>\n      <td>1</td>\n      <td>607</td>\n      <td>So speaking of software that nobody understan...</td>\n      <td>[so, speaking, of, software, that, nobody, und...</td>\n      <td>[-0.15644458, -0.12002514, 0.52115595, -0.0703...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>1</td>\n      <td>608</td>\n      <td>But what are your thoughts on deep learning? ...</td>\n      <td>[but, what, are, your, thoughts, on, deep, lea...</td>\n      <td>[-0.09975407, -0.10085674, 0.75640166, -0.0454...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>1</td>\n      <td>609</td>\n      <td>What are your thoughts about the promise limi...</td>\n      <td>[what, are, your, thoughts, about, the, promis...</td>\n      <td>[0.25803897, -0.4572116, 0.67869514, -0.127189...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>1</td>\n      <td>610</td>\n      <td>One of them is when you look at the human bra...</td>\n      <td>[one, of, them, is, when, you, look, at, the, ...</td>\n      <td>[-0.06427292, -0.3188045, 0.48247167, -0.53355...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>1</td>\n      <td>611</td>\n      <td></td>\n      <td>[]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>611 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\n# Obtener los centroides de cada cluster\ncentroides = kmeans.cluster_centers_\n\n# Función para encontrar la similitud coseno entre un vector y el centroide de un cluster\ndef obtener_similitud_con_centroide(embedding, centroide):\n    return cosine_similarity([embedding], [centroide])[0][0]\n\n# Crear un diccionario para almacenar las oraciones más representativas de cada cluster\noraciones_topico = {}\n\n# Iterar sobre cada cluster y encontrar las oraciones más cercanas al centroide\nfor cluster_id in range(n_clusters):\n    # Obtener las oraciones en este cluster\n    oraciones_cluster = df_modelado[df_modelado['cluster'] == cluster_id]\n    \n    # Obtener los embeddings de estas oraciones\n    embeddings_cluster = np.array(oraciones_cluster['embedding'].tolist())\n    \n    # Calcular la similitud coseno entre cada embedding y el centroide del cluster\n    similitudes = [obtener_similitud_con_centroide(embedding, centroides[cluster_id]) for embedding in embeddings_cluster]\n    \n    # Encontrar el índice de la oración más cercana al centroide\n    indice_max_similitud = np.argmax(similitudes)\n    \n    # Obtener la oración más representativa y asociarla con el cluster\n    oracion_representativa = oraciones_cluster.iloc[indice_max_similitud]['text']\n    \n    # Guardar la oración más representativa en el diccionario\n    oraciones_topico[cluster_id] = oracion_representativa\n\n# Mostrar las oraciones más representativas de cada cluster (tópico)\nfor cluster_id, oracion in oraciones_topico.items():\n    print(f\"Cluster {cluster_id}: {oracion}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:36:47.885123Z","iopub.execute_input":"2025-01-14T14:36:47.885525Z","iopub.status.idle":"2025-01-14T14:38:14.752907Z","shell.execute_reply.started":"2025-01-14T14:36:47.885494Z","shell.execute_reply":"2025-01-14T14:38:14.751605Z"}},"outputs":[{"name":"stdout","text":"Cluster 0:  If you end up with a list of like, well, these are things we never want to see, that list leaks, and after the passage of some time, certainly couldn't be done today, but after the passage of some time, lots and lots of people in academic labs going all the way down to the high school level are in a position to make it overly simplistic, hit print on a genome and have the virus bearing that genome pop out on the other end and you've got something to worry about, but in general, computational biology I think is incredibly important, particularly because the crushing majority of work that people are doing with the protein folding problem and other things are about creating therapeutics, about creating things that will help us live better, live longer, thrive, be more well, and so forth, and the protein folding problem is a monstrous computational challenge that we seem to make just the most glacial project on, I'm sorry, progress on for years and years, but I think there's a biannual competition I think for which people tackle the protein folding problem, and Deep Mind's entrant both two years ago, like in 2018 and 2020, ruled the field, and so protein folding is an unbelievably important thing if you want to start thinking about therapeutics because it's the folding of the protein that tells us where the channels and the receptors and everything else are on that protein, and it's from that precise model, if we can get to a precise model, that you can start barraging it again in silicone with thousands, tens of thousands, millions of potential therapeutics and see what resolves the problems, the shortcomings that a misshapen protein, for instance, somebody with cystic fibrosis, how might we treat that? So I see nothing but good in that\nCluster 1:  And he said something about Diane and it wasn't good, but I didn't, he goes, why didn't you say something? I said, daddy, I just boy talk, you know? So, you know, and so he hugged me, he hugged me, he hugged me and, you know, it was one of these things that it's definitely made me a lot of who I am because there's been a lot of choices and I don't, I took the word choice out of my life and I just like to say, okay, do the right thing, do the thing that you should do\nCluster 2:  Yeah\nCluster 3:  Or that same person could say that'll be longterm healthy for the platform or for the platform's influence on society outside of the platform, right? And it, you know, it's easy for me to sit here and say these things, but conceptually I do not think that these are kind of totally or should, they shouldn't be kind of completely alien ideas, right? That, you know, you could try things like this and it wouldn't be, you know, we wouldn't have to invent entirely new science to do it because if we're all already embedded in some metric space and there's a notion of distance between you and me and every other, every piece of content, then, you know, we know exactly, you know, the same model that tells, you know, dictates how to make me really happy also tells how to make me as unhappy as possible as well\nCluster 4:  It's just, it's such a great privilege to exist that, that yeah, it's just, I think that's the scary part\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Crear un DataFrame con los tópicos y sus oraciones representativas\ntopicos_df = pd.DataFrame(list(oraciones_topico.items()), columns=['Cluster', 'Oracion Representativa'])\n\ndef obtener_embedding_busqueda(clave, modelo):\n    tokens = clave.split()\n    vectores = [modelo.wv[word] for word in tokens if word in modelo.wv]\n    if len(vectores) > 0:\n        return np.mean(vectores, axis=0)\n    else:\n        return np.zeros(modelo.vector_size)\n\n# Función para realizar la búsqueda\ndef buscar_por_topico(clave, modelo, df_modelado, top_n=5):\n    # Obtener el embedding de las palabras clave\n    embedding_busqueda = obtener_embedding_busqueda(clave, modelo)\n    \n    # Calcular la similitud coseno entre el embedding de búsqueda y los embeddings de las oraciones\n    embeddings_oraciones = np.array(df_modelado['embedding'].tolist())\n    similitudes = cosine_similarity([embedding_busqueda], embeddings_oraciones)[0]\n    \n    # Ordenar las oraciones por similitud\n    df_modelado['similitud'] = similitudes\n    resultados = df_modelado[['ep_id', 'sentence_id', 'text', 'similitud']].sort_values(by='similitud', ascending=False).head(top_n)\n    \n    return resultados\n\n# Realizar la búsqueda\nclave_busqueda = \"deep learning\"\nresultados_busqueda = buscar_por_topico(clave_busqueda, model, df_modelado)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:51:14.070850Z","iopub.execute_input":"2025-01-14T14:51:14.071255Z","iopub.status.idle":"2025-01-14T14:51:14.893865Z","shell.execute_reply.started":"2025-01-14T14:51:14.071221Z","shell.execute_reply":"2025-01-14T14:51:14.892774Z"}},"outputs":[],"execution_count":68}]}